#!/usr/bin/env python3
"""
í‘œì • ì¸ì‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import torch
import mlflow.pytorch
import numpy as np
from PIL import Image
import cv2
import os

def test_expression_model():
    """í‘œì • ì¸ì‹ ëª¨ë¸ì„ ë¡œë“œí•˜ê³  í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    
    print("ğŸ¤– í‘œì • ì¸ì‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        # MLflow ëª¨ë¸ ë¡œë“œ
        model_path = "models"
        print(f"ğŸ“ ëª¨ë¸ ê²½ë¡œ: {os.path.abspath(model_path)}")
        
        # ëª¨ë¸ ë¡œë“œ
        print("ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘...")
        model = mlflow.pytorch.load_model(model_path)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        
        # ëª¨ë¸ ì •ë³´ ì¶œë ¥
        print(f"ğŸ“Š ëª¨ë¸ íƒ€ì…: {type(model)}")
        print(f"ğŸ“Š ëª¨ë¸ êµ¬ì¡°: {model}")
        
        # ëª¨ë¸ì´ GPU ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ–¥ï¸ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
        
        # ëª¨ë¸ì„ GPUë¡œ ì´ë™
        if torch.cuda.is_available():
            model = model.to(device)
            print("âœ… ëª¨ë¸ì„ GPUë¡œ ì´ë™ ì™„ë£Œ")
        
        # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
        model.eval()
        print("âœ… ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •")
        
        # ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸
        print("ğŸ§ª ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸...")
        
        # ViT ëª¨ë¸ì€ 224x224 í¬ê¸° í•„ìš”
        height, width = 224, 224
        
        # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± (RGB)
        dummy_input = torch.randn(1, 3, height, width)
        if torch.cuda.is_available():
            dummy_input = dummy_input.to(device)
        
        print(f"ğŸ“ ì…ë ¥ í¬ê¸°: {dummy_input.shape}")
        
        # ì¶”ë¡  ì‹¤í–‰
        with torch.no_grad():
            output = model(dummy_input)
        
        print(f"ğŸ“¤ ì¶œë ¥ íƒ€ì…: {type(output)}")
        print(f"ğŸ“¤ ì¶œë ¥ ë‚´ìš©: {output}")
        
        # ImageClassifierOutputì—ì„œ logits ì¶”ì¶œ
        if hasattr(output, 'logits'):
            logits = output.logits
            print(f"ğŸ“Š Logits í¬ê¸°: {logits.shape}")
            print(f"ğŸ“Š Logits ê°’ ë²”ìœ„: {logits.min().item():.4f} ~ {logits.max().item():.4f}")
            print(f"ğŸ“Š Logits í‰ê· : {logits.mean().item():.4f}")
            
            # ì†Œí”„íŠ¸ë§¥ìŠ¤ ì ìš©í•˜ì—¬ í™•ë¥ ë¡œ ë³€í™˜
            probabilities = torch.softmax(logits, dim=1)
            print(f"ğŸ“Š í™•ë¥  í•©ê³„: {probabilities.sum().item():.4f}")
            print(f"ğŸ“Š í™•ë¥  ê°’: {probabilities[0].tolist()}")
            
            # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤
            predicted_class = torch.argmax(probabilities, dim=1)
            confidence = probabilities[0][predicted_class].item()
            print(f"ğŸ¯ ì˜ˆì¸¡ í´ë˜ìŠ¤: {predicted_class.item()}")
            print(f"ğŸ¯ ì‹ ë¢°ë„: {confidence:.4f}")
        
        # ëª¨ë¸ì˜ forward ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í™•ì¸
        print("\nğŸ” ëª¨ë¸ forward ë©”ì„œë“œ ë¶„ì„...")
        if hasattr(model, 'forward'):
            import inspect
            sig = inspect.signature(model.forward)
            print(f"ğŸ“ Forward ì‹œê·¸ë‹ˆì²˜: {sig}")
        
        # ëª¨ë¸ì˜ í´ë˜ìŠ¤ ì •ë³´ í™•ì¸
        print(f"ğŸ“ ëª¨ë¸ í´ë˜ìŠ¤: {model.__class__.__name__}")
        print(f"ğŸ“ ëª¨ë¸ ëª¨ë“ˆ: {model.__class__.__module__}")
        
        return model, device
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None, None

def analyze_expression_capabilities(model, device):
    """ëª¨ë¸ì˜ í‘œì • ì¸ì‹ ê¸°ëŠ¥ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
    
    print("\nğŸ­ í‘œì • ì¸ì‹ ê¸°ëŠ¥ ë¶„ì„...")
    
    # ViT ëª¨ë¸ì˜ ì¶œë ¥ í´ë˜ìŠ¤ ìˆ˜ í™•ì¸
    if hasattr(model, 'classifier'):
        num_classes = model.classifier.out_features
        print(f"ğŸ“Š ì¶œë ¥ í´ë˜ìŠ¤ ìˆ˜: {num_classes}")
        
        # ì¼ë°˜ì ì¸ í‘œì • ì¹´í…Œê³ ë¦¬
        expression_categories = {
            7: ['happy', 'sad', 'angry', 'surprised', 'fearful', 'disgusted', 'neutral'],
            8: ['happy', 'sad', 'angry', 'surprised', 'fearful', 'disgusted', 'neutral', 'contempt'],
            6: ['happy', 'sad', 'angry', 'surprised', 'fearful', 'disgusted'],
            2: ['positive', 'negative']
        }
        
        if num_classes in expression_categories:
            print(f"ğŸ¯ ì¶”ì • í‘œì • ì¹´í…Œê³ ë¦¬: {expression_categories[num_classes]}")
        else:
            print(f"ğŸ¯ {num_classes}ê°€ì§€ í‘œì • ì¹´í…Œê³ ë¦¬ (ì •í™•í•œ ë§¤í•‘ í•„ìš”)")
    
    # ëª¨ë¸ì˜ ì…ë ¥ ì „ì²˜ë¦¬ ìš”êµ¬ì‚¬í•­ í™•ì¸
    print("\nğŸ”§ ëª¨ë¸ ì…ë ¥ ìš”êµ¬ì‚¬í•­:")
    print("âœ… ì…ë ¥ í¬ê¸°: 224x224 (ViT í‘œì¤€)")
    print("âœ… ì…ë ¥ ì±„ë„: RGB (3ì±„ë„)")
    print("âœ… ì…ë ¥ ì •ê·œí™”: í•„ìš” (ImageNet í‘œì¤€)")
    print("âœ… ë°°ì¹˜ ì°¨ì›: ì§€ì›")

def create_expression_analyzer():
    """í‘œì • ë¶„ì„ê¸°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    
    print("\nğŸ”§ í‘œì • ë¶„ì„ê¸° ìƒì„±...")
    
    # ëª¨ë¸ ë¡œë“œ
    model, device = test_expression_model()
    
    if model is None:
        print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
        return None
    
    # í‘œì • ë¶„ì„ ê¸°ëŠ¥ ë¶„ì„
    analyze_expression_capabilities(model, device)
    
    def analyze_expression(image_tensor):
        """ì´ë¯¸ì§€ í…ì„œì—ì„œ í‘œì •ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        try:
            # ì…ë ¥ ì „ì²˜ë¦¬
            if image_tensor.shape != (1, 3, 224, 224):
                # í¬ê¸° ì¡°ì • í•„ìš”
                print(f"âš ï¸ ì…ë ¥ í¬ê¸° ì¡°ì • í•„ìš”: {image_tensor.shape} -> (1, 3, 224, 224)")
                return None
            
            # GPUë¡œ ì´ë™
            if device.type == 'cuda':
                image_tensor = image_tensor.to(device)
            
            # ì¶”ë¡ 
            with torch.no_grad():
                output = model(image_tensor)
            
            # ê²°ê³¼ ì²˜ë¦¬
            if hasattr(output, 'logits'):
                logits = output.logits
                probabilities = torch.softmax(logits, dim=1)
                
                # ê²°ê³¼ ë°˜í™˜
                return {
                    'logits': logits.cpu().numpy(),
                    'probabilities': probabilities.cpu().numpy(),
                    'predicted_class': torch.argmax(probabilities, dim=1).cpu().numpy(),
                    'confidence': probabilities.max().cpu().numpy()
                }
            
        except Exception as e:
            print(f"âŒ í‘œì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None
    
    return analyze_expression

if __name__ == "__main__":
    print("ğŸš€ í‘œì • ì¸ì‹ ëª¨ë¸ ë¶„ì„ ì‹œì‘")
    print("=" * 50)
    
    # ëª¨ë¸ ë¡œë“œ ë° í…ŒìŠ¤íŠ¸
    model, device = test_expression_model()
    
    if model is not None:
        # í‘œì • ì¸ì‹ ê¸°ëŠ¥ ë¶„ì„
        analyze_expression_capabilities(model, device)
        
        print("\n" + "=" * 50)
        print("âœ… ëª¨ë¸ ë¶„ì„ ì™„ë£Œ!")
        print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
        print("1. MediaPipeì™€ í†µí•©í•˜ì—¬ ì‹¤ì‹œê°„ í‘œì • ë¶„ì„")
        print("2. ì›¹ ì¸í„°í˜ì´ìŠ¤ì—ì„œ ëª¨ë¸ í˜¸ì¶œ")
        print("3. í‘œì • ì ìˆ˜ ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸")
        print("4. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•")
    else:
        print("\nâŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
