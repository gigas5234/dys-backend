#!/usr/bin/env python3
"""
ì‹¤ì‹œê°„ í‘œì • ë¶„ì„ê¸° - MediaPipe + PyTorch ViT ëª¨ë¸ í†µí•©
"""

import torch
import numpy as np
import cv2
from PIL import Image
import base64
import io
import os
from typing import Dict, Any, Optional

# MLflowëŠ” ì„ íƒì ìœ¼ë¡œ import
try:
    import mlflow.pytorch
    MLFLOW_AVAILABLE = True
except ImportError:
    MLFLOW_AVAILABLE = False
    print("âš ï¸ MLflow ì—†ìŒ - PyTorch ì§ì ‘ ë¡œë“œ ë°©ì‹ ì‚¬ìš©")

class ExpressionAnalyzer:
    """MediaPipeì™€ PyTorch ViT ëª¨ë¸ì„ í†µí•©í•œ ì‹¤ì‹œê°„ í‘œì • ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.model = None
        self.device = None
        self.expression_categories = [
            'happy', 'sad', 'angry', 'surprised', 'fearful', 'disgusted', 'neutral', 'contempt'
        ]
        self.is_initialized = False
        
    def initialize(self):
        """ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        try:
            print("ğŸ¤– í‘œì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹œì‘...")
            
            # ëª¨ë¸ íŒŒì¼ ê²½ë¡œë“¤ (Google Storageì—ì„œ ë‹¤ìš´ë¡œë“œëœ .pth íŒŒì¼)
            model_file_paths = [
                # Google Storageì—ì„œ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼
                os.path.join(os.path.dirname(__file__), "models", "data", "model.pth"),
                # ì„œë²„ ì‹¤í–‰ ë””ë ‰í† ë¦¬ ê¸°ì¤€
                os.path.join(os.getcwd(), "src", "dys_studio", "models", "data", "model.pth"),
                os.path.join(os.getcwd(), "dys_studio", "models", "data", "model.pth"),
                # ì ˆëŒ€ ê²½ë¡œ
                "/workspace/app/dys_studio/models/data/model.pth",
                "/usr/src/app/dys_studio/models/data/model.pth"
            ]
            
            # MLflow ëª¨ë¸ ê²½ë¡œë“¤ (ë§Œì•½ ìˆë‹¤ë©´)
            mlflow_paths = [
                os.path.join(os.path.dirname(__file__), "models"),
                os.path.join(os.getcwd(), "src", "dys_studio", "models"),
                os.path.join(os.getcwd(), "dys_studio", "models"),
                "/workspace/app/dys_studio/models",
                "/usr/src/app/dys_studio/models"
            ]
            
            model_loaded = False
            
            # 1. MLflow ëª¨ë¸ ë¡œë“œ ì‹œë„ (ìš°ì„ )
            if MLFLOW_AVAILABLE:
                for model_path in mlflow_paths:
                    try:
                        print(f"ğŸ“ MLflow ëª¨ë¸ ê²½ë¡œ ì‹œë„: {os.path.abspath(model_path)}")
                        if os.path.exists(model_path) and os.path.exists(os.path.join(model_path, "MLmodel")):
                            print("ğŸ”„ MLflow ëª¨ë¸ ë¡œë”© ì¤‘...")
                            import mlflow.pytorch
                            # CPU ë§¤í•‘ìœ¼ë¡œ CUDA í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°
                            self.model = mlflow.pytorch.load_model(model_path, map_location='cpu')
                            
                            # ViT ëª¨ë¸ì¸ ê²½ìš° config ì†ì„± í™•ì¸ ë° ì¶”ê°€
                            if hasattr(self.model, 'config'):
                                if not hasattr(self.model.config, 'output_attentions'):
                                    self.model.config.output_attentions = False
                                    print("ğŸ”§ output_attentions ì†ì„± ì¶”ê°€")
                                if not hasattr(self.model.config, 'output_hidden_states'):
                                    self.model.config.output_hidden_states = False
                                    print("ğŸ”§ output_hidden_states ì†ì„± ì¶”ê°€")
                                if not hasattr(self.model.config, 'use_return_dict'):
                                    self.model.config.use_return_dict = True
                                    print("ğŸ”§ use_return_dict ì†ì„± ì¶”ê°€")
                            
                            print(f"âœ… MLflow ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
                            model_loaded = True
                            break
                    except Exception as e:
                        print(f"âš ï¸ MLflow ëª¨ë¸ ê²½ë¡œ ì‹¤íŒ¨: {model_path} - {e}")
                        continue
            
            # 2. PyTorch ì§ì ‘ ë¡œë“œ ì‹œë„ (.pth íŒŒì¼)
            if not model_loaded:
                for model_file in model_file_paths:
                    try:
                        print(f"ğŸ“ PyTorch ëª¨ë¸ íŒŒì¼ ì‹œë„: {os.path.abspath(model_file)}")
                        if os.path.exists(model_file):
                            print("ğŸ”„ PyTorch ëª¨ë¸ ë¡œë”© ì¤‘...")
                            
                            # transformers ëª¨ë¸ì¸ ê²½ìš° ì²˜ë¦¬
                            try:
                                # ë¨¼ì € ì¼ë°˜ PyTorch ëª¨ë¸ë¡œ ì‹œë„
                                self.model = torch.load(model_file, map_location='cpu')
                                
                                # ViT ëª¨ë¸ì¸ ê²½ìš° config ì†ì„± í™•ì¸ ë° ì¶”ê°€
                                if hasattr(self.model, 'config'):
                                    if not hasattr(self.model.config, 'output_attentions'):
                                        self.model.config.output_attentions = False
                                        print("ğŸ”§ output_attentions ì†ì„± ì¶”ê°€")
                                    if not hasattr(self.model.config, 'output_hidden_states'):
                                        self.model.config.output_hidden_states = False
                                        print("ğŸ”§ output_hidden_states ì†ì„± ì¶”ê°€")
                                    if not hasattr(self.model.config, 'use_return_dict'):
                                        self.model.config.use_return_dict = True
                                        print("ğŸ”§ use_return_dict ì†ì„± ì¶”ê°€")
                                
                                print(f"âœ… PyTorch ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_file}")
                                model_loaded = True
                                break
                            except Exception as pytorch_error:
                                print(f"âš ï¸ ì¼ë°˜ PyTorch ë¡œë“œ ì‹¤íŒ¨: {pytorch_error}")
                                
                                # transformers ëª¨ë¸ë¡œ ì‹œë„
                                try:
                                    print("ğŸ”„ Transformers ëª¨ë¸ë¡œ ì¬ì‹œë„...")
                                    
                                    # Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ìˆëŠ” ê²½ìš° ì‹¤ì œ ëª¨ë¸ ë¡œë“œ
                                    try:
                                        from transformers import ViTForImageClassification, ViTConfig
                                        print("âœ… Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸ë¨")
                                        
                                        # ì‹¤ì œ ëª¨ë¸ íŒŒì¼ì—ì„œ ë¡œë“œ
                                        # ë¨¼ì € ì €ì¥ëœ ëª¨ë¸ íƒ€ì… í™•ì¸
                                        model_dict = torch.load(model_file, map_location='cpu')
                                        print(f"ğŸ” ëª¨ë¸ ë”•ì…”ë„ˆë¦¬ í‚¤: {list(model_dict.keys())}")
                                        
                                        # í˜¸í™˜ ê°€ëŠ¥í•œ ViT ì„¤ì •ìœ¼ë¡œ ëª¨ë¸ ìƒì„±
                                        try:
                                            # ìµœì‹  ë²„ì „ìš© ì„¤ì •
                                            config = ViTConfig(
                                                image_size=224,
                                                patch_size=16,
                                                num_channels=3,
                                                num_labels=8,  # 8ê°œ ê°ì • ì¹´í…Œê³ ë¦¬
                                                hidden_size=768,
                                                num_hidden_layers=12,
                                                num_attention_heads=12,
                                                intermediate_size=3072,
                                                output_attentions=False,  # ëª…ì‹œì ìœ¼ë¡œ False ì„¤ì •
                                                output_hidden_states=False,
                                                use_return_dict=True
                                            )
                                        except TypeError:
                                            # êµ¬ë²„ì „ í˜¸í™˜ ì„¤ì • (output_attentions ì†ì„±ì´ ì—†ëŠ” ê²½ìš°)
                                            config = ViTConfig(
                                                image_size=224,
                                                patch_size=16,
                                                num_channels=3,
                                                num_labels=8,  # 8ê°œ ê°ì • ì¹´í…Œê³ ë¦¬
                                                hidden_size=768,
                                                num_hidden_layers=12,
                                                num_attention_heads=12,
                                                intermediate_size=3072
                                            )
                                        
                                        # ìƒˆ ëª¨ë¸ ìƒì„±
                                        self.model = ViTForImageClassification(config)
                                        
                                        # ViTConfigì— ëˆ„ë½ëœ ì†ì„±ë“¤ ê°•ì œ ì¶”ê°€
                                        if not hasattr(self.model.config, 'output_attentions'):
                                            self.model.config.output_attentions = False
                                        if not hasattr(self.model.config, 'output_hidden_states'):
                                            self.model.config.output_hidden_states = False
                                        if not hasattr(self.model.config, 'use_return_dict'):
                                            self.model.config.use_return_dict = True
                                        
                                        # ì €ì¥ëœ ëª¨ë¸ì´ state_dict í˜•íƒœì¸ì§€ í™•ì¸í•˜ê³  ë¡œë“œ
                                        if isinstance(model_dict, dict):
                                            if 'state_dict' in model_dict:
                                                state_dict = model_dict['state_dict']
                                            elif 'model_state_dict' in model_dict:
                                                state_dict = model_dict['model_state_dict']
                                            else:
                                                # ì „ì²´ê°€ state_dictì¸ ê²½ìš°
                                                state_dict = model_dict
                                            
                                            # í‚¤ ì´ë¦„ ì •ë¦¬ (ëª¨ë¸ í”„ë¦¬í”½ìŠ¤ ì œê±°)
                                            cleaned_state_dict = {}
                                            for key, value in state_dict.items():
                                                new_key = key.replace('model.', '').replace('module.', '')
                                                cleaned_state_dict[new_key] = value
                                            
                                            # strict=Falseë¡œ í˜¸í™˜ë˜ì§€ ì•ŠëŠ” í‚¤ ë¬´ì‹œ
                                            missing_keys, unexpected_keys = self.model.load_state_dict(cleaned_state_dict, strict=False)
                                            if missing_keys:
                                                print(f"âš ï¸ ëˆ„ë½ëœ í‚¤: {len(missing_keys)}ê°œ")
                                            if unexpected_keys:
                                                print(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ í‚¤: {len(unexpected_keys)}ê°œ")
                                        else:
                                            # ì§ì ‘ ëª¨ë¸ ê°ì²´ì¸ ê²½ìš°
                                            self.model = model_dict
                                        
                                        print(f"âœ… ViT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_file}")
                                        model_loaded = True
                                        break
                                        
                                    except ImportError:
                                        print("âš ï¸ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ - ë”ë¯¸ ëª¨ë¸ ìƒì„±")
                                        # ê°œë°œìš© ë”ë¯¸ ëª¨ë¸
                                        import torch.nn as nn
                                        
                                        class DummyExpressionModel(nn.Module):
                                            def __init__(self):
                                                super().__init__()
                                                self.classifier = nn.Linear(768, 8)  # 8ê°œ í‘œì • í´ë˜ìŠ¤
                                                
                                            def forward(self, x):
                                                # ë”ë¯¸ ê²°ê³¼ ìƒì„±
                                                batch_size = x.shape[0] if len(x.shape) > 0 else 1
                                                logits = torch.randn(batch_size, 8)  # 8ê°œ í‘œì •
                                                
                                                # ImageClassifierOutput ìŠ¤íƒ€ì¼ ê°ì²´ ìƒì„±
                                                class Output:
                                                    def __init__(self, logits):
                                                        self.logits = logits
                                                
                                                return Output(logits)
                                        
                                        self.model = DummyExpressionModel()
                                        print(f"âš ï¸ ë”ë¯¸ í‘œì • ë¶„ì„ ëª¨ë¸ ìƒì„± (ê°œë°œìš©): {model_file}")
                                        model_loaded = True
                                        break
                                    
                                except Exception as transformers_error:
                                    print(f"âš ï¸ Transformers ëª¨ë¸ ë¡œë“œë„ ì‹¤íŒ¨: {transformers_error}")
                                    continue
                                    
                    except Exception as e:
                        print(f"âš ï¸ ëª¨ë¸ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {model_file} - {e}")
                        continue
            
            if not model_loaded:
                print("âŒ ëª¨ë“  ëª¨ë¸ ê²½ë¡œì—ì„œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("âš ï¸ í‘œì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨ - ëª¨ë¸ íŒŒì¼ ì—†ìŒ")
                print("ğŸ” í™•ì¸ëœ ê²½ë¡œë“¤:")
                for path in model_file_paths + mlflow_paths:
                    print(f"   - {os.path.abspath(path)} (ì¡´ì¬: {os.path.exists(path)})")
                return False
            
            # GPU ì„¤ì • ë° ìƒì„¸ ì •ë³´ ì¶œë ¥
            cuda_available = torch.cuda.is_available()
            print(f"ğŸ–¥ï¸ CUDA ì§€ì› ìƒíƒœ: {cuda_available}")
            
            if cuda_available:
                print(f"ğŸ® GPU ê°œìˆ˜: {torch.cuda.device_count()}")
                print(f"ğŸ® í˜„ì¬ GPU: {torch.cuda.current_device()}")
                print(f"ğŸ® GPU ì´ë¦„: {torch.cuda.get_device_name(0)}")
                print(f"ğŸ® GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
                print(f"ğŸ® CUDA ë²„ì „: {torch.version.cuda}")
            else:
                print("âš ï¸ CUDAê°€ ì§€ì›ë˜ì§€ ì•ŠëŠ” í™˜ê²½ì…ë‹ˆë‹¤. CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                
            self.device = torch.device('cuda' if cuda_available else 'cpu')
            print(f"ğŸ–¥ï¸ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")
            
            # ëª¨ë¸ì„ GPUë¡œ ì´ë™
            if cuda_available:
                self.model = self.model.to(self.device)
                print("âœ… ëª¨ë¸ì„ GPUë¡œ ì´ë™ ì™„ë£Œ")
            else:
                print("ğŸ’» CPU ëª¨ë“œë¡œ ëª¨ë¸ ì‹¤í–‰")
            
            # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
            self.model.eval()
            print("âœ… ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •")
            
            self.is_initialized = True
            print("âœ… í‘œì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ!")
            
            return True
            
        except Exception as e:
            print(f"âŒ í‘œì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def preprocess_image(self, image_data: str) -> Optional[torch.Tensor]:
        """Base64 ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        try:
            # Base64 ë””ì½”ë”©
            if image_data.startswith('data:image'):
                # data:image/jpeg;base64, í˜•íƒœ ì œê±°
                image_data = image_data.split(',')[1]
            
            # ì´ë¯¸ì§€ ë””ì½”ë”©
            image_bytes = base64.b64decode(image_data)
            image = Image.open(io.BytesIO(image_bytes))
            
            # RGB ë³€í™˜
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # í¬ê¸° ì¡°ì • (224x224)
            image = image.resize((224, 224), Image.Resampling.LANCZOS)
            
            # NumPy ë°°ì—´ë¡œ ë³€í™˜
            image_array = np.array(image).astype(np.float32)
            
            # ì •ê·œí™” (0-255 -> 0-1)
            image_array = image_array / 255.0
            
            # ImageNet ì •ê·œí™” (í‰ê· , í‘œì¤€í¸ì°¨)
            mean = np.array([0.485, 0.456, 0.406])
            std = np.array([0.229, 0.224, 0.225])
            
            # ì±„ë„ë³„ ì •ê·œí™”
            for i in range(3):
                image_array[:, :, i] = (image_array[:, :, i] - mean[i]) / std[i]
            
            # í…ì„œë¡œ ë³€í™˜ ë° ì°¨ì› ì¡°ì • (HWC -> CHW)
            image_tensor = torch.from_numpy(image_array).permute(2, 0, 1)
            
            # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            image_tensor = image_tensor.unsqueeze(0)
            
            return image_tensor
            
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None
    
    def analyze_expression(self, image_data: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ì—ì„œ í‘œì •ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        if not self.is_initialized:
            print("âŒ í‘œì • ë¶„ì„ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {
                'success': False,
                'error': 'Expression analyzer not initialized'
            }
        
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            image_tensor = self.preprocess_image(image_data)
            if image_tensor is None:
                return {
                    'success': False,
                    'error': 'Image preprocessing failed'
                }
            
            # GPUë¡œ ì´ë™
            if self.device.type == 'cuda':
                image_tensor = image_tensor.to(self.device)
            
            # ëª¨ë¸ config ì†ì„± ì¬í™•ì¸ (ëŸ°íƒ€ì„ ì•ˆì „ì¥ì¹˜)
            if hasattr(self.model, 'config'):
                if not hasattr(self.model.config, 'output_attentions'):
                    self.model.config.output_attentions = False
                if not hasattr(self.model.config, 'output_hidden_states'):
                    self.model.config.output_hidden_states = False
                if not hasattr(self.model.config, 'use_return_dict'):
                    self.model.config.use_return_dict = True
            
            # ì¶”ë¡ 
            with torch.no_grad():
                output = self.model(image_tensor)
            
            # ê²°ê³¼ ì²˜ë¦¬
            if hasattr(output, 'logits'):
                logits = output.logits
                probabilities = torch.softmax(logits, dim=1)
                
                # ê²°ê³¼ ì¶”ì¶œ
                probs = probabilities[0].cpu().numpy()
                predicted_class = torch.argmax(probabilities, dim=1).cpu().numpy()[0]
                confidence = probabilities.max().cpu().numpy()
                
                # í‘œì • ì¹´í…Œê³ ë¦¬ ë§¤í•‘
                expression = self.expression_categories[predicted_class]
                
                # ê²°ê³¼ ë°˜í™˜
                result = {
                    'success': True,
                    'expression': expression,
                    'confidence': float(confidence),
                    'predicted_class': int(predicted_class),
                    'probabilities': {
                        cat: float(prob) for cat, prob in zip(self.expression_categories, probs)
                    },
                    'all_probabilities': probs.tolist()
                }
                
                print(f"ğŸ­ í‘œì • ë¶„ì„ ê²°ê³¼: {expression} (ì‹ ë¢°ë„: {confidence:.3f})")
                return result
            
        except Exception as e:
            print(f"âŒ í‘œì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'error': str(e)
            }
    
    def get_expression_score(self, expression_result: Dict[str, Any]) -> Dict[str, Any]:
        """í‘œì • ë¶„ì„ ê²°ê³¼ë¥¼ ì ìˆ˜ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        if not expression_result.get('success', False):
            return {
                'score': 0,
                'label': 'ë¶„ì„ ì‹¤íŒ¨',
                'details': expression_result.get('error', 'Unknown error')
            }
        
        expression = expression_result['expression']
        confidence = expression_result['confidence']
        
        # í‘œì •ë³„ ì ìˆ˜ ë§¤í•‘ (ê°œì„ ëœ ì ìˆ˜ ì‹œìŠ¤í…œ)
        expression_scores = {
            'happy': 95,      # ë§¤ìš° ë†’ì€ ì ìˆ˜
            'neutral': 85,    # ë†’ì€ ì ìˆ˜ (ì¤‘ë¦½ì ì´ì§€ë§Œ ê¸ì •ì )
            'surprised': 75,  # ê¸ì •ì  ì ìˆ˜
            'sad': 45,        # ì¤‘ê°„ ì ìˆ˜
            'angry': 25,      # ë‚®ì€ ì ìˆ˜
            'fearful': 30,    # ë‚®ì€ ì ìˆ˜
            'disgusted': 20,  # ë§¤ìš° ë‚®ì€ ì ìˆ˜
            'contempt': 35    # ë‚®ì€ ì ìˆ˜
        }
        
        # ê¸°ë³¸ ì ìˆ˜
        base_score = expression_scores.get(expression, 60)
        
        # ì‹ ë¢°ë„ì— ë”°ë¥¸ ì ìˆ˜ ì¡°ì • (ì‹ ë¢°ë„ê°€ ë†’ì„ìˆ˜ë¡ ì ìˆ˜ ë³´ë„ˆìŠ¤)
        confidence_bonus = 1.0 + (confidence - 0.5) * 0.4  # ì‹ ë¢°ë„ 50% ì´ìƒì—ì„œ ë³´ë„ˆìŠ¤
        adjusted_score = int(base_score * confidence_bonus)
        
        # ì ìˆ˜ ë²”ìœ„ ì œí•œ (ìµœì†Œ 20ì  ë³´ì¥)
        final_score = max(20, min(100, adjusted_score))
        
        # ë¼ë²¨ ìƒì„± (ê°œì„ ëœ ë¼ë²¨ ì‹œìŠ¤í…œ)
        if final_score >= 85:
            label = "ë§¤ìš° ê¸ì •ì "
        elif final_score >= 70:
            label = "ê¸ì •ì "
        elif final_score >= 50:
            label = "ì¤‘ë¦½ì "
        elif final_score >= 30:
            label = "ë¶€ì •ì "
        else:
            label = "ë§¤ìš° ë¶€ì •ì "
        
        return {
            'score': final_score,
            'label': label,
            'expression': expression,
            'confidence': confidence,
            'base_score': base_score,
            'confidence_bonus': confidence_bonus,
            'expression_scores': expression_scores,
            'details': f"{expression} í‘œì • (ì‹ ë¢°ë„: {confidence:.2f}, ê¸°ë³¸ì ìˆ˜: {base_score}, ìµœì¢…ì ìˆ˜: {final_score})"
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
expression_analyzer = ExpressionAnalyzer()

def initialize_expression_analyzer():
    """í‘œì • ë¶„ì„ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    return expression_analyzer.initialize()

def analyze_expression_from_image(image_data: str) -> Dict[str, Any]:
    """ì´ë¯¸ì§€ì—ì„œ í‘œì •ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
    return expression_analyzer.analyze_expression(image_data)

def get_expression_score_from_result(expression_result: Dict[str, Any]) -> Dict[str, Any]:
    """í‘œì • ë¶„ì„ ê²°ê³¼ë¥¼ ì ìˆ˜ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    return expression_analyzer.get_expression_score(expression_result)

if __name__ == "__main__":
    print("ğŸš€ í‘œì • ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ì´ˆê¸°í™”
    if initialize_expression_analyzer():
        print("âœ… í‘œì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì„±ê³µ!")
        
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± (ë”ë¯¸)
        print("\nğŸ§ª ë”ë¯¸ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸...")
        dummy_image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
        dummy_image_pil = Image.fromarray(dummy_image)
        
        # PIL ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ë³€í™˜
        buffer = io.BytesIO()
        dummy_image_pil.save(buffer, format='JPEG')
        dummy_image_base64 = base64.b64encode(buffer.getvalue()).decode()
        
        # í‘œì • ë¶„ì„
        result = analyze_expression_from_image(dummy_image_base64)
        print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼: {result}")
        
        if result['success']:
            # ì ìˆ˜ ë³€í™˜
            score_result = get_expression_score_from_result(result)
            print(f"ğŸ“ˆ ì ìˆ˜ ê²°ê³¼: {score_result}")
        
        print("\n" + "=" * 50)
        print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    else:
        print("âŒ í‘œì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨")
