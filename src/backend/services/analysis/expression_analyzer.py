#!/usr/bin/env python3
"""
ì‹¤ì‹œê°„ í‘œì • ë¶„ì„ê¸° - MLflow PyTorch ëª¨ë¸ í†µí•©
"""

import torch
import numpy as np
import cv2
from PIL import Image
import base64
import io
import os
from typing import Dict, Any, Optional, List, Tuple
import logging

# ìƒˆë¡œìš´ êµ¬ì¡°ì— ë§ê²Œ import ê²½ë¡œ ìˆ˜ì •
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', '..'))

# MLflowëŠ” ì„ íƒì ìœ¼ë¡œ import
try:
    import mlflow.pytorch
    MLFLOW_AVAILABLE = True
except ImportError:
    MLFLOW_AVAILABLE = False
    print("âš ï¸ MLflow ì—†ìŒ - PyTorch ì§ì ‘ ë¡œë“œ ë°©ì‹ ì‚¬ìš©")

class ExpressionAnalyzer:
    """MLflow PyTorch ëª¨ë¸ì„ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ í‘œì • ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.model = None
        self.device = None
        self.expression_categories = [
            'happy', 'sad', 'angry', 'surprised', 'fearful', 'disgusted', 'neutral', 'contempt'
        ]
        self.is_initialized = False
        self.logger = logging.getLogger(__name__)
        
    def _ensure_vit_runtime_compat(self):
        """Transformers ë²„ì „/ê°€ì¤‘ì¹˜ ë¶ˆì¼ì¹˜ë¡œ ì¸í•œ ëŸ°íƒ€ì„ ì˜¤ë¥˜ë¥¼ ì˜ˆë°©í•˜ê¸° ìœ„í•œ í˜¸í™˜ì„± íŒ¨ì¹˜."""
        try:
            import torch.nn as nn
        except Exception:
            return
        
        # config í•„ë“œ ë³´ê°•
        if hasattr(self.model, 'config'):
            cfg = self.model.config
            if not hasattr(cfg, 'output_attentions'):
                cfg.output_attentions = False
            if not hasattr(cfg, 'output_hidden_states'):
                cfg.output_hidden_states = False
            if not hasattr(cfg, 'use_return_dict'):
                cfg.use_return_dict = True
            if not hasattr(cfg, 'attention_probs_dropout_prob'):
                cfg.attention_probs_dropout_prob = 0.0
        
        def patch_module(m):
            # ViT Self-Attention ê³„ì¸µì— dropout ì†ì„±ì´ ì—†ëŠ” ê²½ìš° ì£¼ì…
            class_name = m.__class__.__name__
            if class_name == 'ViTSelfAttention':
                if not hasattr(m, 'dropout'):
                    p = 0.0
                    try:
                        if hasattr(self.model, 'config') and hasattr(self.model.config, 'attention_probs_dropout_prob'):
                            p = float(self.model.config.attention_probs_dropout_prob)
                    except Exception:
                        p = 0.0
                    try:
                        m.dropout = nn.Dropout(p)
                        self.logger.info(f"ğŸ”§ ViTSelfAttention.dropout ì¶”ê°€(p={p})")
                    except Exception:
                        m.dropout = nn.Identity()
                        self.logger.info("ğŸ”§ ViTSelfAttention.dropout=Identity()ë¡œ ëŒ€ì²´")
            return m
        
        # í•˜ìœ„ ëª¨ë“ˆ ìˆœíšŒí•˜ë©° íŒ¨ì¹˜ ì ìš©
        try:
            for name, module in self.model.named_modules():
                patch_module(module)
        except Exception as e:
            self.logger.warning(f"âš ï¸ ViT í˜¸í™˜ì„± íŒ¨ì¹˜ ì¤‘ ê²½ê³ : {e}")
        
    def initialize(self):
        """ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        try:
            self.logger.info("ğŸ¤– í‘œì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹œì‘...")
            
            # MLflow ëª¨ë¸ ê²½ë¡œë“¤ (ìš°ì„ ìˆœìœ„ ìˆœì„œ)
            mlflow_paths = [
                # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ (ê°€ì¥ ìš°ì„ )
                os.path.join(os.path.dirname(__file__), "models"),
                # ì„œë²„ ì‹¤í–‰ ë””ë ‰í† ë¦¬ ê¸°ì¤€
                os.path.join(os.getcwd(), "src", "backend", "models", "ml_models"),
                os.path.join(os.getcwd(), "backend", "models", "ml_models"),
                # GKE í™˜ê²½ ì ˆëŒ€ ê²½ë¡œ
                "/workspace/app/src/backend/models/ml_models",
                "/usr/src/app/src/backend/models/ml_models",
                # ì¶”ê°€ ê°€ëŠ¥í•œ ê²½ë¡œë“¤
                "/app/src/backend/models/ml_models",
                "/opt/app/src/backend/models/ml_models"
            ]
            
            model_loaded = False
            
            # MLflow ëª¨ë¸ ë¡œë“œ ì‹œë„
            if MLFLOW_AVAILABLE:
                self.logger.info("ğŸ”„ MLflow ëª¨ë¸ ë¡œë”© ì‹œë„ ì¤‘...")
                for model_path in mlflow_paths:
                    try:
                        self.logger.info(f"ğŸ“ MLflow ëª¨ë¸ ê²½ë¡œ ì‹œë„: {os.path.abspath(model_path)}")
                        if os.path.exists(model_path) and os.path.exists(os.path.join(model_path, "MLmodel")):
                            self.logger.info("ğŸ”„ MLflow ëª¨ë¸ ë¡œë”© ì¤‘...")
                            
                            # MLflow ëª¨ë¸ ë¡œë“œ (CPU ë§¤í•‘ìœ¼ë¡œ CUDA í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°)
                            # PyTorch ë²„ì „ ë¶ˆì¼ì¹˜ ê²½ê³  ë¬´ì‹œ
                            import warnings
                            with warnings.catch_warnings():
                                warnings.filterwarnings("ignore", category=UserWarning)
                                
                                try:
                                    # ë¨¼ì € MLflowë¡œ ì‹œë„
                                    self.model = mlflow.pytorch.load_model(
                                        model_path, 
                                        map_location='cpu'
                                    )
                                except Exception as mlflow_error:
                                    self.logger.warning(f"âš ï¸ MLflow ë¡œë”© ì‹¤íŒ¨, ì§ì ‘ PyTorch ë¡œë”© ì‹œë„: {mlflow_error}")
                                    
                                    # MLflow ì‹¤íŒ¨ì‹œ ì§ì ‘ PyTorchë¡œ ë¡œë“œ
                                    import torch
                                    model_file = os.path.join(model_path, "data", "model.pth")
                                    if os.path.exists(model_file):
                                        self.model = torch.load(model_file, map_location='cpu', weights_only=False)
                                        self.logger.info(f"âœ… ì§ì ‘ PyTorch ë¡œë”© ì„±ê³µ: {model_file}")
                                    else:
                                        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {model_file}")
                            
                            # ViT ëª¨ë¸ í˜¸í™˜ì„± íŒ¨ì¹˜ ì ìš©
                            self._ensure_vit_runtime_compat()
                            
                            self.logger.info(f"âœ… MLflow ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
                            self.logger.info(f"ğŸ“Š ëª¨ë¸ ì •ë³´: {type(self.model)}")
                            model_loaded = True
                            self.is_initialized = True
                            break
                        else:
                            self.logger.warning(f"âš ï¸ MLflow ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
                            self.logger.warning(f"   - ë””ë ‰í† ë¦¬ ì¡´ì¬: {os.path.exists(model_path)}")
                            self.logger.warning(f"   - MLmodel íŒŒì¼ ì¡´ì¬: {os.path.exists(os.path.join(model_path, 'MLmodel'))}")
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ MLflow ëª¨ë¸ ê²½ë¡œ ì‹¤íŒ¨: {model_path}")
                        self.logger.warning(f"   - ì˜¤ë¥˜: {e}")
                        import traceback
                        traceback.print_exc()
                        continue
            else:
                self.logger.warning("âš ï¸ MLflowê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥ - PyTorch ì§ì ‘ ë¡œë“œë¡œ ì§„í–‰")
            
            # PyTorch ì§ì ‘ ë¡œë“œ ì‹œë„ (.pth íŒŒì¼)
            if not model_loaded:
                model_file_paths = [
                    os.environ.get('MODEL_PATH'),  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¨¼ì € í™•ì¸
                    os.path.join(os.path.dirname(__file__), "models", "data", "model.pth"),
                    os.path.join(os.getcwd(), "src", "backend", "models", "ml_models", "data", "model.pth"),
                    os.path.join(os.getcwd(), "backend", "models", "ml_models", "data", "model.pth"),
                    "/workspace/app/src/backend/models/ml_models/data/model.pth",
                    "/usr/src/app/src/backend/models/ml_models/data/model.pth"
                ]
                
                for model_file in model_file_paths:
                    try:
                        self.logger.info(f"ğŸ“ PyTorch ëª¨ë¸ íŒŒì¼ ì‹œë„: {os.path.abspath(model_file)}")
                        if os.path.exists(model_file):
                            self.logger.info("ğŸ”„ PyTorch ëª¨ë¸ ë¡œë”© ì¤‘...")
                            
                            # transformers ëª¨ë¸ì¸ ê²½ìš° ì²˜ë¦¬
                            try:
                                # ë¨¼ì € ì¼ë°˜ PyTorch ëª¨ë¸ë¡œ ì‹œë„
                                self.model = torch.load(model_file, map_location='cpu')
                                
                                # ViT ëª¨ë¸ì¸ ê²½ìš° config ì†ì„± í™•ì¸ ë° ì¶”ê°€
                                if hasattr(self.model, 'config'):
                                    if not hasattr(self.model.config, 'output_attentions'):
                                        self.model.config.output_attentions = False
                                        self.logger.info("ğŸ”§ output_attentions ì†ì„± ì¶”ê°€")
                                    if not hasattr(self.model.config, 'output_hidden_states'):
                                        self.model.config.output_hidden_states = False
                                        self.logger.info("ğŸ”§ output_hidden_states ì†ì„± ì¶”ê°€")
                                    if not hasattr(self.model.config, 'use_return_dict'):
                                        self.model.config.use_return_dict = True
                                        self.logger.info("ğŸ”§ use_return_dict ì†ì„± ì¶”ê°€")
                                
                                self.logger.info(f"âœ… PyTorch ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_file}")
                                model_loaded = True
                                self.is_initialized = True
                                break
                            except Exception as pytorch_error:
                                self.logger.warning(f"âš ï¸ ì¼ë°˜ PyTorch ë¡œë“œ ì‹¤íŒ¨: {pytorch_error}")
                                
                                # transformers ëª¨ë¸ë¡œ ì‹œë„
                                try:
                                    self.logger.info("ğŸ”„ Transformers ëª¨ë¸ë¡œ ì¬ì‹œë„...")
                                    
                                    # Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ìˆëŠ” ê²½ìš° ì‹¤ì œ ëª¨ë¸ ë¡œë“œ
                                    try:
                                        from transformers import ViTForImageClassification, ViTConfig
                                        self.logger.info("âœ… Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸ë¨")
                                        
                                        # ì‹¤ì œ ëª¨ë¸ íŒŒì¼ì—ì„œ ë¡œë“œ
                                        # ë¨¼ì € ì €ì¥ëœ ëª¨ë¸ íƒ€ì… í™•ì¸
                                        model_dict = torch.load(model_file, map_location='cpu')
                                        self.logger.info(f"ğŸ” ëª¨ë¸ ë”•ì…”ë„ˆë¦¬ í‚¤: {list(model_dict.keys())}")
                                        
                                        # í˜¸í™˜ ê°€ëŠ¥í•œ ViT ì„¤ì •ìœ¼ë¡œ ëª¨ë¸ ìƒì„±
                                        try:
                                            # ìµœì‹  ë²„ì „ìš© ì„¤ì •
                                            config = ViTConfig(
                                                image_size=384,  # ê³ í™”ì§ˆ ëŒ€ì‘
                                                patch_size=16,
                                                num_channels=3,
                                                num_labels=8,  # 8ê°œ ê°ì • ì¹´í…Œê³ ë¦¬
                                                hidden_size=768,
                                                num_hidden_layers=12,
                                                num_attention_heads=12,
                                                intermediate_size=3072,
                                                output_attentions=False,  # ëª…ì‹œì ìœ¼ë¡œ False ì„¤ì •
                                                output_hidden_states=False,
                                                use_return_dict=True
                                            )
                                        except TypeError:
                                            # êµ¬ë²„ì „ í˜¸í™˜ ì„¤ì • (output_attentions ì†ì„±ì´ ì—†ëŠ” ê²½ìš°)
                                            config = ViTConfig(
                                                image_size=384,  # ê³ í™”ì§ˆ ëŒ€ì‘
                                                patch_size=16,
                                                num_channels=3,
                                                num_labels=8,  # 8ê°œ ê°ì • ì¹´í…Œê³ ë¦¬
                                                hidden_size=768,
                                                num_hidden_layers=12,
                                                num_attention_heads=12,
                                                intermediate_size=3072
                                            )
                                        
                                        # ìƒˆ ëª¨ë¸ ìƒì„±
                                        self.model = ViTForImageClassification(config)
                                        
                                        # ViTConfigì— ëˆ„ë½ëœ ì†ì„±ë“¤ ê°•ì œ ì¶”ê°€
                                        if not hasattr(self.model.config, 'output_attentions'):
                                            self.model.config.output_attentions = False
                                        if not hasattr(self.model.config, 'output_hidden_states'):
                                            self.model.config.output_hidden_states = False
                                        if not hasattr(self.model.config, 'use_return_dict'):
                                            self.model.config.use_return_dict = True
                                        
                                        # ì €ì¥ëœ ëª¨ë¸ì´ state_dict í˜•íƒœì¸ì§€ í™•ì¸í•˜ê³  ë¡œë“œ
                                        if isinstance(model_dict, dict):
                                            if 'state_dict' in model_dict:
                                                state_dict = model_dict['state_dict']
                                            elif 'model_state_dict' in model_dict:
                                                state_dict = model_dict['model_state_dict']
                                            else:
                                                # ì „ì²´ê°€ state_dictì¸ ê²½ìš°
                                                state_dict = model_dict
                                            
                                            # í‚¤ ì´ë¦„ ì •ë¦¬ (ëª¨ë¸ í”„ë¦¬í”½ìŠ¤ ì œê±°)
                                            cleaned_state_dict = {}
                                            for key, value in state_dict.items():
                                                new_key = key.replace('model.', '').replace('module.', '')
                                                cleaned_state_dict[new_key] = value
                                            
                                            # strict=Falseë¡œ í˜¸í™˜ë˜ì§€ ì•ŠëŠ” í‚¤ ë¬´ì‹œ
                                            missing_keys, unexpected_keys = self.model.load_state_dict(cleaned_state_dict, strict=False)
                                            if missing_keys:
                                                self.logger.warning(f"âš ï¸ ëˆ„ë½ëœ í‚¤: {len(missing_keys)}ê°œ")
                                            if unexpected_keys:
                                                self.logger.warning(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ í‚¤: {len(unexpected_keys)}ê°œ")
                                        else:
                                            # ì§ì ‘ ëª¨ë¸ ê°ì²´ì¸ ê²½ìš°
                                            self.model = model_dict
                                        
                                        self.logger.info(f"âœ… ViT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_file}")
                                        model_loaded = True
                                        self.is_initialized = True
                                        break
                                        
                                    except ImportError:
                                        self.logger.warning("âš ï¸ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ - ë”ë¯¸ ëª¨ë¸ ìƒì„±")
                                        # ê°œë°œìš© ë”ë¯¸ ëª¨ë¸
                                        import torch.nn as nn
                                        
                                        class DummyExpressionModel(nn.Module):
                                            def __init__(self):
                                                super().__init__()
                                                self.classifier = nn.Linear(768, 8)  # 8ê°œ í‘œì • í´ë˜ìŠ¤
                                                
                                            def forward(self, x):
                                                # ë”ë¯¸ ê²°ê³¼ ìƒì„±
                                                batch_size = x.shape[0] if len(x.shape) > 0 else 1
                                                logits = torch.randn(batch_size, 8)  # 8ê°œ í‘œì •
                                                
                                                # ImageClassifierOutput ìŠ¤íƒ€ì¼ ê°ì²´ ìƒì„±
                                                class Output:
                                                    def __init__(self, logits):
                                                        self.logits = logits
                                                
                                                return Output(logits)
                                        
                                        self.model = DummyExpressionModel()
                                        self.logger.warning(f"âš ï¸ ë”ë¯¸ í‘œì • ë¶„ì„ ëª¨ë¸ ìƒì„± (ê°œë°œìš©): {model_file}")
                                        model_loaded = True
                                        self.is_initialized = True
                                        break
                                    
                                except Exception as transformers_error:
                                    self.logger.warning(f"âš ï¸ Transformers ëª¨ë¸ ë¡œë“œë„ ì‹¤íŒ¨: {transformers_error}")
                                    continue
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ PyTorch ëª¨ë¸ íŒŒì¼ ì‹¤íŒ¨: {model_file}")
                        self.logger.warning(f"   - ì˜¤ë¥˜: {e}")
                        continue
            
            if not model_loaded:
                self.logger.error("âŒ ëª¨ë“  ëª¨ë¸ ë¡œë“œ ì‹œë„ ì‹¤íŒ¨")
                return False
            
            # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
            self.model.eval()
            
            # CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ë° ì„¤ì •
            if torch.cuda.is_available():
                self.device = torch.device('cuda')
                self.model = self.model.to(self.device)
                self.logger.info("ğŸš€ CUDA ì‚¬ìš© ê°€ëŠ¥ - GPU ê°€ì† í™œì„±í™”")
            else:
                self.device = torch.device('cpu')
                self.logger.info("ğŸ’» CPU ëª¨ë“œë¡œ ì‹¤í–‰")
            
            self.logger.info("âœ… í‘œì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ í‘œì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False

    def preprocess_image(self, image_data: str) -> Optional[torch.Tensor]:
        """ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        try:
            # Base64 ë””ì½”ë”©
            if image_data.startswith('data:image'):
                # data:image/jpeg;base64, í˜•íƒœ ì œê±°
                image_data = image_data.split(',')[1]
            
            # Base64 ë””ì½”ë”©
            image_bytes = base64.b64decode(image_data)
            image = Image.open(io.BytesIO(image_bytes))
            
            # RGB ë³€í™˜
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # ë¦¬ì‚¬ì´ì¦ˆ (384x384) - ê³ í™”ì§ˆ ëŒ€ì‘
            image = image.resize((384, 384), Image.Resampling.LANCZOS)
            
            # numpy ë°°ì—´ë¡œ ë³€í™˜
            image_array = np.array(image)
            
            # ì •ê·œí™” (0-1 ë²”ìœ„)
            image_array = image_array.astype(np.float32) / 255.0
            
            # PyTorch í…ì„œë¡œ ë³€í™˜
            image_tensor = torch.from_numpy(image_array).permute(2, 0, 1)  # HWC -> CHW
            
            # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            image_tensor = image_tensor.unsqueeze(0)
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            image_tensor = image_tensor.to(self.device)
            
            return image_tensor
            
        except Exception as e:
            self.logger.error(f"âŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None

    def analyze_expression(self, image_data: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ì—ì„œ í‘œì •ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        try:
            if not self.is_initialized:
                self.logger.error("âŒ ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                return {
                    'success': False,
                    'error': 'Model not initialized',
                    'expressions': {},
                    'dominant_expression': None,
                    'confidence': 0.0
                }
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            image_tensor = self.preprocess_image(image_data)
            if image_tensor is None:
                return {
                    'success': False,
                    'error': 'Image preprocessing failed',
                    'expressions': {},
                    'dominant_expression': None,
                    'confidence': 0.0
                }
            
            # ëª¨ë¸ ì¶”ë¡ 
            with torch.no_grad():
                outputs = self.model(image_tensor)
                
                # logits ì¶”ì¶œ
                if hasattr(outputs, 'logits'):
                    logits = outputs.logits
                else:
                    logits = outputs
                
                # ì†Œí”„íŠ¸ë§¥ìŠ¤ ì ìš©í•˜ì—¬ í™•ë¥  ê³„ì‚°
                probabilities = torch.softmax(logits, dim=1)
                
                # CPUë¡œ ì´ë™í•˜ì—¬ numpyë¡œ ë³€í™˜
                probabilities = probabilities.cpu().numpy()[0]
                
                # ê²°ê³¼ êµ¬ì„±
                expressions = {}
                for i, category in enumerate(self.expression_categories):
                    expressions[category] = float(probabilities[i])
                
                # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í‘œì • ì°¾ê¸°
                dominant_idx = np.argmax(probabilities)
                dominant_expression = self.expression_categories[dominant_idx]
                confidence = float(probabilities[dominant_idx])
                
                return {
                    'success': True,
                    'expressions': expressions,
                    'dominant_expression': dominant_expression,
                    'confidence': confidence,
                    'probabilities': probabilities.tolist()
                }
                
        except Exception as e:
            self.logger.error(f"âŒ í‘œì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'error': str(e),
                'expressions': {},
                'dominant_expression': None,
                'confidence': 0.0
            }

    def analyze_expression_batch(self, image_data_list: List[str]) -> List[Dict[str, Any]]:
        """ì—¬ëŸ¬ ì´ë¯¸ì§€ì˜ í‘œì •ì„ ì¼ê´„ ë¶„ì„í•©ë‹ˆë‹¤."""
        results = []
        for image_data in image_data_list:
            result = self.analyze_expression(image_data)
            results.append(result)
        return results

    def get_expression_summary(self, analysis_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì—¬ëŸ¬ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìš”ì•½í•©ë‹ˆë‹¤."""
        try:
            if not analysis_results:
                return {
                    'success': False,
                    'error': 'No analysis results',
                    'summary': {}
                }
            
            # ì„±ê³µí•œ ê²°ê³¼ë§Œ í•„í„°ë§
            successful_results = [r for r in analysis_results if r.get('success', False)]
            
            if not successful_results:
                return {
                    'success': False,
                    'error': 'No successful analysis results',
                    'summary': {}
                }
            
            # ê° í‘œì •ë³„ í‰ê·  í™•ë¥  ê³„ì‚°
            expression_sums = {category: 0.0 for category in self.expression_categories}
            expression_counts = {category: 0 for category in self.expression_categories}
            
            for result in successful_results:
                expressions = result.get('expressions', {})
                for category, probability in expressions.items():
                    expression_sums[category] += probability
                    expression_counts[category] += 1
            
            # í‰ê·  ê³„ì‚°
            expression_averages = {}
            for category in self.expression_categories:
                if expression_counts[category] > 0:
                    expression_averages[category] = expression_sums[category] / expression_counts[category]
                else:
                    expression_averages[category] = 0.0
            
            # ê°€ì¥ ë§ì´ ë‚˜íƒ€ë‚œ í‘œì • ì°¾ê¸°
            dominant_expression = max(expression_averages.items(), key=lambda x: x[1])
            
            return {
                'success': True,
                'summary': {
                    'expression_averages': expression_averages,
                    'dominant_expression': dominant_expression[0],
                    'dominant_confidence': dominant_expression[1],
                    'total_analyses': len(successful_results),
                    'success_rate': len(successful_results) / len(analysis_results)
                }
            }
            
        except Exception as e:
            self.logger.error(f"âŒ í‘œì • ë¶„ì„ ìš”ì•½ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'summary': {}
            }
    
    def analyze_expression_sync(self, image) -> Dict[str, Any]:
        """
        ë™ê¸°ì‹ í‘œì • ë¶„ì„ (í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œìš©)
        
        Args:
            image: OpenCV í˜•ì‹ ì´ë¯¸ì§€ (BGR)
            
        Returns:
            Dict: ë¶„ì„ ê²°ê³¼ {'success': bool, 'emotion': str, 'confidence': float, ...}
        """
        try:
            self.logger.info("ğŸ§  [EXPRESSION_SYNC] ë™ê¸°ì‹ í‘œì • ë¶„ì„ ì‹œì‘")
            
            if not self.is_initialized or not self.model:
                self.logger.warning("âš ï¸ [EXPRESSION_SYNC] ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                return {
                    "success": False,
                    "error": "ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ",
                    "emotion": "neutral",
                    "confidence": 0.0,
                    "happiness": 0.0,
                    "sadness": 0.0,
                    "anger": 0.0,
                    "surprise": 0.0
                }
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_image = self._preprocess_image(image)
            if processed_image is None:
                return {
                    "success": False,
                    "error": "ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨",
                    "emotion": "neutral", 
                    "confidence": 0.0,
                    "happiness": 0.0,
                    "sadness": 0.0,
                    "anger": 0.0,
                    "surprise": 0.0
                }
            
            # ëª¨ë¸ ì¶”ë¡ 
            self.model.eval()
            with torch.no_grad():
                if processed_image.dim() == 3:
                    processed_image = processed_image.unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
                
                # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPUë¡œ, ì•„ë‹ˆë©´ CPUë¡œ
                processed_image = processed_image.to(self.device)
                
                outputs = self.model(processed_image)
                
                # ê²°ê³¼ ì²˜ë¦¬ (ëª¨ë¸ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥´ê²Œ)
                if hasattr(outputs, 'logits'):
                    logits = outputs.logits
                else:
                    logits = outputs
                
                # ì†Œí”„íŠ¸ë§¥ìŠ¤ë¡œ í™•ë¥  ê³„ì‚°
                probabilities = torch.softmax(logits, dim=1)
                predicted_class = torch.argmax(probabilities, dim=1).item()
                confidence = torch.max(probabilities).item()
                
                # ê°ì • ë ˆì´ë¸” ë§¤í•‘
                emotion = self.expression_categories[predicted_class] if predicted_class < len(self.expression_categories) else "neutral"
                
                # ê° ê°ì •ë³„ í™•ë¥  ê³„ì‚°
                emotion_scores = {}
                for i, category in enumerate(self.expression_categories):
                    if i < probabilities.shape[1]:
                        emotion_scores[category] = probabilities[0][i].item()
                
                self.logger.info(f"âœ… [EXPRESSION_SYNC] ë¶„ì„ ì™„ë£Œ: {emotion} (ì‹ ë¢°ë„: {confidence:.3f})")
                
                return {
                    "success": True,
                    "emotion": emotion,
                    "confidence": confidence,
                    "expression": confidence * 100,  # UIì—ì„œ ì‚¬ìš©í•˜ëŠ” í˜•ì‹
                    "concentration": emotion_scores.get('neutral', 0.5) * 100,  # ì¤‘ë¦½ì¼ ë•Œ ì§‘ì¤‘ë„ ë†’ìŒ
                    "happiness": emotion_scores.get('happy', 0.0) * 100,
                    "sadness": emotion_scores.get('sad', 0.0) * 100,
                    "anger": emotion_scores.get('angry', 0.0) * 100,
                    "surprise": emotion_scores.get('surprised', 0.0) * 100,
                    "fear": emotion_scores.get('fearful', 0.0) * 100,
                    "disgust": emotion_scores.get('disgusted', 0.0) * 100,
                    "neutral": emotion_scores.get('neutral', 0.0) * 100,
                    "all_scores": emotion_scores,
                    "predicted_class": predicted_class,
                    "processing_device": str(self.device)
                }
                
        except Exception as e:
            self.logger.error(f"âŒ [EXPRESSION_SYNC] ë™ê¸°ì‹ ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            
            return {
                "success": False,
                "error": str(e),
                "emotion": "neutral",
                "confidence": 0.0,
                "happiness": 0.0,
                "sadness": 0.0,
                "anger": 0.0,
                "surprise": 0.0
            }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
expression_analyzer = ExpressionAnalyzer()
